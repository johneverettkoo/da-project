{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers, optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras import backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "import gc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "# matplotlib.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOV_VALS = [30, 40, 50, 60, 70]\n",
    "FOV_VALS = [70, 60, 50, 40, 30]\n",
    "\n",
    "PARENT_DIR = '/media/johnkoo/data/stanford-dogs-dataset/'\n",
    "val_dir = os.path.join(PARENT_DIR, 'val')\n",
    "test_dir = os.path.join(PARENT_DIR, 'test')\n",
    "\n",
    "NUM_CLASSES = 120\n",
    "\n",
    "INPUT_SHAPE = (128, 128, 3)\n",
    "\n",
    "BATCH_SIZE = 160\n",
    "\n",
    "RUNS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(val_dir)\n",
    "val_x = np.load('val-images.npy') / 255.\n",
    "val_y = np.load('val-labels.npy')\n",
    "\n",
    "os.chdir(test_dir)\n",
    "test_x = np.load('test-images.npy') / 255.\n",
    "test_y = np.load('test-labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_SIZE = 120\n",
    "\n",
    "dogs = np.unique(val_y)\n",
    "dogs_subset = np.random.choice(dogs, SUBSET_SIZE, replace=False)\n",
    "\n",
    "val_ind = np.where(np.isin(val_y, dogs_subset))[0]\n",
    "test_ind = np.where(np.isin(test_y, dogs_subset))[0]\n",
    "\n",
    "val_x = val_x[val_ind, :, :, :]\n",
    "test_x = test_x[test_ind, :, :, :]\n",
    "\n",
    "val_y = val_y[val_ind]\n",
    "test_y = test_y[test_ind]\n",
    "\n",
    "y_dict = dict([(y, x) for x, y in enumerate(sorted(set(val_y)))])\n",
    "\n",
    "y_val = np.asarray([y_dict[x] for x in val_y])\n",
    "y_test = np.asarray([y_dict[x] for x in test_y])\n",
    "\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 36s 6ms/step - loss: 4.8154 - acc: 0.0078 - val_loss: 4.7877 - val_acc: 0.0117\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7063 - acc: 0.0280 - val_loss: 4.7605 - val_acc: 0.0160\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.4218 - acc: 0.0643 - val_loss: 4.7180 - val_acc: 0.0253\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.8744 - acc: 0.1195 - val_loss: 4.9244 - val_acc: 0.0320\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.3371 - acc: 0.2068 - val_loss: 4.6402 - val_acc: 0.0483\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.6840 - acc: 0.3247 - val_loss: 4.7263 - val_acc: 0.0670\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.0554 - acc: 0.4715 - val_loss: 4.9023 - val_acc: 0.0647\n",
      "4222/4222 [==============================] - 8s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8149 - acc: 0.0090 - val_loss: 4.7850 - val_acc: 0.0123\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6327 - acc: 0.0337 - val_loss: 4.7190 - val_acc: 0.0167\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.1755 - acc: 0.0760 - val_loss: 4.7743 - val_acc: 0.0267\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.4884 - acc: 0.1752 - val_loss: 4.6245 - val_acc: 0.0520\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.9079 - acc: 0.2818 - val_loss: 4.4744 - val_acc: 0.0757\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.1651 - acc: 0.4382 - val_loss: 4.7439 - val_acc: 0.0747\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.4255 - acc: 0.6193 - val_loss: 4.8570 - val_acc: 0.0863\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8227 - acc: 0.0095 - val_loss: 4.7845 - val_acc: 0.0107\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.7052 - acc: 0.0277 - val_loss: 4.7703 - val_acc: 0.0183\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.3923 - acc: 0.0620 - val_loss: 4.7149 - val_acc: 0.0267\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.8760 - acc: 0.1305 - val_loss: 4.6912 - val_acc: 0.0363\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.1939 - acc: 0.2302 - val_loss: 4.5164 - val_acc: 0.0500\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.5059 - acc: 0.3690 - val_loss: 4.6863 - val_acc: 0.0653\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.8967 - acc: 0.5062 - val_loss: 4.9850 - val_acc: 0.0657\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8051 - acc: 0.0113 - val_loss: 4.7899 - val_acc: 0.0117\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6679 - acc: 0.0287 - val_loss: 4.7488 - val_acc: 0.0173\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.2483 - acc: 0.0700 - val_loss: 4.7837 - val_acc: 0.0170\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.6677 - acc: 0.1403 - val_loss: 4.7040 - val_acc: 0.0327\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.0739 - acc: 0.2555 - val_loss: 4.4495 - val_acc: 0.0543\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.4572 - acc: 0.3688 - val_loss: 4.8498 - val_acc: 0.0547\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.8184 - acc: 0.5238 - val_loss: 4.9068 - val_acc: 0.0720\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8192 - acc: 0.0095 - val_loss: 4.7917 - val_acc: 0.0087\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6669 - acc: 0.0345 - val_loss: 4.7327 - val_acc: 0.0227\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.2981 - acc: 0.0657 - val_loss: 4.7196 - val_acc: 0.0277\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.7276 - acc: 0.1425 - val_loss: 4.6795 - val_acc: 0.0347\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.0996 - acc: 0.2395 - val_loss: 4.5860 - val_acc: 0.0537\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.5204 - acc: 0.3652 - val_loss: 4.8361 - val_acc: 0.0627\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.9362 - acc: 0.4975 - val_loss: 4.8933 - val_acc: 0.0743\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8151 - acc: 0.0098 - val_loss: 4.7771 - val_acc: 0.0120\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6341 - acc: 0.0355 - val_loss: 4.6939 - val_acc: 0.0203\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.1684 - acc: 0.0808 - val_loss: 4.5851 - val_acc: 0.0393\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 30s 5ms/step - loss: 3.4975 - acc: 0.1815 - val_loss: 4.4326 - val_acc: 0.0587\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.8081 - acc: 0.2988 - val_loss: 4.5177 - val_acc: 0.0607\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.1878 - acc: 0.4463 - val_loss: 4.6877 - val_acc: 0.0760\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8208 - acc: 0.0093 - val_loss: 4.7830 - val_acc: 0.0103\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6828 - acc: 0.0262 - val_loss: 4.7392 - val_acc: 0.0163\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3392 - acc: 0.0568 - val_loss: 4.6746 - val_acc: 0.0263\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.8173 - acc: 0.1222 - val_loss: 4.5916 - val_acc: 0.0420\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.2228 - acc: 0.2205 - val_loss: 4.5749 - val_acc: 0.0553\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.5943 - acc: 0.3502 - val_loss: 4.8376 - val_acc: 0.0700\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8621 - acc: 0.5110 - val_loss: 5.2490 - val_acc: 0.0640\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8232 - acc: 0.0075 - val_loss: 4.7884 - val_acc: 0.0120\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.7258 - acc: 0.0220 - val_loss: 4.7720 - val_acc: 0.0110\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.4792 - acc: 0.0523 - val_loss: 4.7708 - val_acc: 0.0230\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.9601 - acc: 0.1012 - val_loss: 4.6917 - val_acc: 0.0300\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.3661 - acc: 0.2017 - val_loss: 4.5426 - val_acc: 0.0497\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.6923 - acc: 0.3235 - val_loss: 4.6558 - val_acc: 0.0600\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.1972 - acc: 0.4277 - val_loss: 4.8789 - val_acc: 0.0707\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8229 - acc: 0.0070 - val_loss: 4.7913 - val_acc: 0.0133\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6670 - acc: 0.0383 - val_loss: 4.7375 - val_acc: 0.0177\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2459 - acc: 0.0743 - val_loss: 4.7148 - val_acc: 0.0273\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.6020 - acc: 0.1665 - val_loss: 4.5109 - val_acc: 0.0503\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.9593 - acc: 0.2705 - val_loss: 4.4307 - val_acc: 0.0637\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3391 - acc: 0.3983 - val_loss: 4.4586 - val_acc: 0.0847\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5958 - acc: 0.5703 - val_loss: 5.0398 - val_acc: 0.0710\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8283 - acc: 0.0057 - val_loss: 4.7916 - val_acc: 0.0103\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7299 - acc: 0.0203 - val_loss: 4.7689 - val_acc: 0.0127\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.4905 - acc: 0.0490 - val_loss: 4.7718 - val_acc: 0.0230\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.9627 - acc: 0.1027 - val_loss: 4.8543 - val_acc: 0.0297\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.7996 - acc: 0.0128 - val_loss: 4.7808 - val_acc: 0.0127\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.5259 - acc: 0.0420 - val_loss: 4.7924 - val_acc: 0.0180\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.9782 - acc: 0.1050 - val_loss: 4.5967 - val_acc: 0.0377\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.3367 - acc: 0.2002 - val_loss: 4.5864 - val_acc: 0.0513\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.6437 - acc: 0.3347 - val_loss: 4.6779 - val_acc: 0.0600\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.0085 - acc: 0.4720 - val_loss: 4.7539 - val_acc: 0.0760\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8167 - acc: 0.0095 - val_loss: 4.7855 - val_acc: 0.0133\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6795 - acc: 0.0280 - val_loss: 4.7451 - val_acc: 0.0177\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.2875 - acc: 0.0688 - val_loss: 4.8206 - val_acc: 0.0167\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.6718 - acc: 0.1432 - val_loss: 4.7386 - val_acc: 0.0373\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.9647 - acc: 0.2717 - val_loss: 4.6949 - val_acc: 0.0533\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.4105 - acc: 0.3873 - val_loss: 4.5795 - val_acc: 0.0720\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.7458 - acc: 0.5398 - val_loss: 5.1743 - val_acc: 0.0670\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.2612 - acc: 0.6598 - val_loss: 5.2603 - val_acc: 0.0840\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8179 - acc: 0.0085 - val_loss: 4.7766 - val_acc: 0.0120\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6635 - acc: 0.0287 - val_loss: 4.7390 - val_acc: 0.0223\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.2174 - acc: 0.0713 - val_loss: 4.8446 - val_acc: 0.0207\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.6525 - acc: 0.1528 - val_loss: 4.7359 - val_acc: 0.0293\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.0397 - acc: 0.2638 - val_loss: 4.6384 - val_acc: 0.0477\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.4205 - acc: 0.3902 - val_loss: 4.7379 - val_acc: 0.0630\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.8484 - acc: 0.5102 - val_loss: 5.3099 - val_acc: 0.0643\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8136 - acc: 0.0098 - val_loss: 4.7866 - val_acc: 0.0110\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6621 - acc: 0.0337 - val_loss: 4.7375 - val_acc: 0.0237\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.2078 - acc: 0.0792 - val_loss: 4.7167 - val_acc: 0.0213\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.5689 - acc: 0.1613 - val_loss: 4.6722 - val_acc: 0.0417\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.0471 - acc: 0.2545 - val_loss: 4.4453 - val_acc: 0.0557\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.3406 - acc: 0.4092 - val_loss: 4.6736 - val_acc: 0.0587\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.8143 - acc: 0.5153 - val_loss: 5.1020 - val_acc: 0.0670\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8111 - acc: 0.0103 - val_loss: 4.7891 - val_acc: 0.0103\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6180 - acc: 0.0425 - val_loss: 4.7728 - val_acc: 0.0120\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.1058 - acc: 0.0882 - val_loss: 4.9289 - val_acc: 0.0217\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.5604 - acc: 0.1663 - val_loss: 4.6271 - val_acc: 0.0393\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.8494 - acc: 0.2997 - val_loss: 4.5238 - val_acc: 0.0593\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.2937 - acc: 0.4172 - val_loss: 4.8572 - val_acc: 0.0623\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.6179 - acc: 0.5718 - val_loss: 5.1185 - val_acc: 0.0703\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8185 - acc: 0.0100 - val_loss: 4.7858 - val_acc: 0.0083\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6723 - acc: 0.0268 - val_loss: 4.7510 - val_acc: 0.0133\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.2773 - acc: 0.0705 - val_loss: 4.7694 - val_acc: 0.0237\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.7085 - acc: 0.1465 - val_loss: 4.6889 - val_acc: 0.0350\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 3.2245 - acc: 0.2325 - val_loss: 4.6112 - val_acc: 0.0440\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.5828 - acc: 0.3428 - val_loss: 4.9122 - val_acc: 0.0557\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.9429 - acc: 0.4918 - val_loss: 5.2809 - val_acc: 0.0640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8242 - acc: 0.0082 - val_loss: 4.7881 - val_acc: 0.0133\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6908 - acc: 0.0265 - val_loss: 4.7280 - val_acc: 0.0183\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3148 - acc: 0.0705 - val_loss: 4.5815 - val_acc: 0.0363\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.6033 - acc: 0.1657 - val_loss: 4.3447 - val_acc: 0.0597\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.8582 - acc: 0.3060 - val_loss: 4.2704 - val_acc: 0.0857\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.1064 - acc: 0.4547 - val_loss: 4.3082 - val_acc: 0.1050\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.3888 - acc: 0.6200 - val_loss: 4.1814 - val_acc: 0.1307\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.8084 - acc: 0.7718 - val_loss: 5.5019 - val_acc: 0.1007\n",
      "Epoch 9/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.3950 - acc: 0.8867 - val_loss: 5.6012 - val_acc: 0.1207\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8225 - acc: 0.0098 - val_loss: 4.7764 - val_acc: 0.0107\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6822 - acc: 0.0323 - val_loss: 4.6949 - val_acc: 0.0187\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2671 - acc: 0.0773 - val_loss: 4.4851 - val_acc: 0.0460\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.5026 - acc: 0.1857 - val_loss: 4.0260 - val_acc: 0.1007\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6903 - acc: 0.3285 - val_loss: 3.9503 - val_acc: 0.1253\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.0342 - acc: 0.4765 - val_loss: 4.0047 - val_acc: 0.1430\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2537 - acc: 0.6567 - val_loss: 4.3656 - val_acc: 0.1467\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8219 - acc: 0.0112 - val_loss: 4.7713 - val_acc: 0.0140\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6620 - acc: 0.0318 - val_loss: 4.6793 - val_acc: 0.0223\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2089 - acc: 0.0772 - val_loss: 4.4488 - val_acc: 0.0493\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4581 - acc: 0.1920 - val_loss: 4.2392 - val_acc: 0.0770\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5985 - acc: 0.3527 - val_loss: 4.4715 - val_acc: 0.0910\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8264 - acc: 0.5175 - val_loss: 4.5832 - val_acc: 0.1153\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8208 - acc: 0.0092 - val_loss: 4.7776 - val_acc: 0.0107\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6828 - acc: 0.0260 - val_loss: 4.7174 - val_acc: 0.0183\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3070 - acc: 0.0690 - val_loss: 4.5370 - val_acc: 0.0413\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.7569 - acc: 0.1467 - val_loss: 4.3676 - val_acc: 0.0620\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.0047 - acc: 0.2698 - val_loss: 4.1070 - val_acc: 0.0993\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.2927 - acc: 0.4200 - val_loss: 4.1817 - val_acc: 0.1113\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.6779 - acc: 0.5545 - val_loss: 4.4465 - val_acc: 0.1063\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8295 - acc: 0.0082 - val_loss: 4.7873 - val_acc: 0.0127\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7299 - acc: 0.0207 - val_loss: 4.7370 - val_acc: 0.0150\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.4770 - acc: 0.0528 - val_loss: 4.6138 - val_acc: 0.0307\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.8811 - acc: 0.1163 - val_loss: 4.3886 - val_acc: 0.0563\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.1681 - acc: 0.2395 - val_loss: 4.0612 - val_acc: 0.0903\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5026 - acc: 0.3698 - val_loss: 4.3156 - val_acc: 0.1023\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7522 - acc: 0.5365 - val_loss: 4.3596 - val_acc: 0.1187\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8205 - acc: 0.0128 - val_loss: 4.7797 - val_acc: 0.0120\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6934 - acc: 0.0223 - val_loss: 4.6966 - val_acc: 0.0220\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3360 - acc: 0.0603 - val_loss: 4.5633 - val_acc: 0.0373\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.6132 - acc: 0.1570 - val_loss: 4.2665 - val_acc: 0.0680\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.8399 - acc: 0.3002 - val_loss: 4.2786 - val_acc: 0.0867\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.0923 - acc: 0.4622 - val_loss: 4.2392 - val_acc: 0.1187\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.3268 - acc: 0.6400 - val_loss: 4.5481 - val_acc: 0.1187\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.8378 - acc: 0.7640 - val_loss: 5.0313 - val_acc: 0.1283\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8233 - acc: 0.0080 - val_loss: 4.7759 - val_acc: 0.0123\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6787 - acc: 0.0295 - val_loss: 4.6962 - val_acc: 0.0193\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2869 - acc: 0.0687 - val_loss: 4.5311 - val_acc: 0.0373\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.5145 - acc: 0.1865 - val_loss: 4.1945 - val_acc: 0.0803\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.7620 - acc: 0.3167 - val_loss: 4.1551 - val_acc: 0.1100\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.9929 - acc: 0.4772 - val_loss: 4.1924 - val_acc: 0.1257\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2698 - acc: 0.6540 - val_loss: 4.7108 - val_acc: 0.1323\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8267 - acc: 0.0087 - val_loss: 4.7880 - val_acc: 0.0107\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7202 - acc: 0.0250 - val_loss: 4.7386 - val_acc: 0.0173\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.4439 - acc: 0.0588 - val_loss: 4.6418 - val_acc: 0.0247\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.8301 - acc: 0.1212 - val_loss: 4.3715 - val_acc: 0.0627\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.0572 - acc: 0.2560 - val_loss: 4.3788 - val_acc: 0.0740\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3856 - acc: 0.3992 - val_loss: 4.2556 - val_acc: 0.0933\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5778 - acc: 0.5837 - val_loss: 4.6978 - val_acc: 0.1027\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.9988 - acc: 0.7218 - val_loss: 5.4592 - val_acc: 0.1183\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8147 - acc: 0.0115 - val_loss: 4.7723 - val_acc: 0.0140\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6199 - acc: 0.0408 - val_loss: 4.6772 - val_acc: 0.0240\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.1310 - acc: 0.0855 - val_loss: 4.5011 - val_acc: 0.0437\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.3864 - acc: 0.2008 - val_loss: 4.3167 - val_acc: 0.0800\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.7155 - acc: 0.3252 - val_loss: 4.2442 - val_acc: 0.0947\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.9630 - acc: 0.4865 - val_loss: 4.1405 - val_acc: 0.1010\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2526 - acc: 0.6568 - val_loss: 4.7807 - val_acc: 0.1173\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.7863 - acc: 0.7762 - val_loss: 5.4130 - val_acc: 0.1263\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8214 - acc: 0.0073 - val_loss: 4.7760 - val_acc: 0.0150\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6569 - acc: 0.0297 - val_loss: 4.7066 - val_acc: 0.0197\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.1785 - acc: 0.0838 - val_loss: 4.5860 - val_acc: 0.0353\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.5467 - acc: 0.1728 - val_loss: 4.2937 - val_acc: 0.0720\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.8786 - acc: 0.2878 - val_loss: 4.1235 - val_acc: 0.1023\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.1123 - acc: 0.4487 - val_loss: 4.1909 - val_acc: 0.1123\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.4533 - acc: 0.6085 - val_loss: 4.4821 - val_acc: 0.1303\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8109 - acc: 0.0135 - val_loss: 4.7787 - val_acc: 0.0137\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6175 - acc: 0.0423 - val_loss: 4.6718 - val_acc: 0.0207\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.0677 - acc: 0.0933 - val_loss: 4.3912 - val_acc: 0.0557\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.2234 - acc: 0.2243 - val_loss: 4.1101 - val_acc: 0.0923\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3360 - acc: 0.3973 - val_loss: 4.0743 - val_acc: 0.1190\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.6524 - acc: 0.5598 - val_loss: 3.9255 - val_acc: 0.1300\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.0587 - acc: 0.7048 - val_loss: 4.4984 - val_acc: 0.1453\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.4802 - acc: 0.8637 - val_loss: 5.5291 - val_acc: 0.1410\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8143 - acc: 0.0092 - val_loss: 4.7751 - val_acc: 0.0133\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6701 - acc: 0.0298 - val_loss: 4.6967 - val_acc: 0.0220\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2420 - acc: 0.0743 - val_loss: 4.5201 - val_acc: 0.0380\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.6826 - acc: 0.1455 - val_loss: 4.3374 - val_acc: 0.0600\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.9871 - acc: 0.2620 - val_loss: 4.3427 - val_acc: 0.0787\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3509 - acc: 0.3955 - val_loss: 4.2358 - val_acc: 0.1083\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7055 - acc: 0.5447 - val_loss: 4.3850 - val_acc: 0.1153\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.0652 - acc: 0.7048 - val_loss: 4.9568 - val_acc: 0.0977\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8176 - acc: 0.0093 - val_loss: 4.7828 - val_acc: 0.0087\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6384 - acc: 0.0335 - val_loss: 4.6854 - val_acc: 0.0257\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.1727 - acc: 0.0855 - val_loss: 4.5587 - val_acc: 0.0417\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.5526 - acc: 0.1683 - val_loss: 4.3003 - val_acc: 0.0737\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.8540 - acc: 0.2993 - val_loss: 4.2392 - val_acc: 0.0883\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.1645 - acc: 0.4358 - val_loss: 4.5079 - val_acc: 0.1027\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5750 - acc: 0.5833 - val_loss: 4.4474 - val_acc: 0.1190\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8082 - acc: 0.0137 - val_loss: 4.7675 - val_acc: 0.0127\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.5802 - acc: 0.0445 - val_loss: 4.6152 - val_acc: 0.0380\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.9094 - acc: 0.1130 - val_loss: 4.3164 - val_acc: 0.0683\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.0263 - acc: 0.2630 - val_loss: 4.1840 - val_acc: 0.0980\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.2028 - acc: 0.4252 - val_loss: 4.0737 - val_acc: 0.1300\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.4822 - acc: 0.6045 - val_loss: 4.0764 - val_acc: 0.1500\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.8747 - acc: 0.7573 - val_loss: 4.8933 - val_acc: 0.1447\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8118 - acc: 0.0123 - val_loss: 4.7631 - val_acc: 0.0150\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.5676 - acc: 0.0450 - val_loss: 4.6421 - val_acc: 0.0267\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.8957 - acc: 0.1240 - val_loss: 4.3066 - val_acc: 0.0567\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.9447 - acc: 0.2713 - val_loss: 3.9016 - val_acc: 0.1123\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.0867 - acc: 0.4482 - val_loss: 3.8069 - val_acc: 0.1510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.3721 - acc: 0.6295 - val_loss: 4.0315 - val_acc: 0.1563\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.7572 - acc: 0.7862 - val_loss: 4.9330 - val_acc: 0.1523\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8193 - acc: 0.0100 - val_loss: 4.7762 - val_acc: 0.0130\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6694 - acc: 0.0317 - val_loss: 4.6880 - val_acc: 0.0213\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2255 - acc: 0.0788 - val_loss: 4.6428 - val_acc: 0.0413\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.5282 - acc: 0.1768 - val_loss: 4.2388 - val_acc: 0.0710\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6546 - acc: 0.3388 - val_loss: 4.1109 - val_acc: 0.0970\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.0056 - acc: 0.4783 - val_loss: 4.0090 - val_acc: 0.1260\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.3183 - acc: 0.6490 - val_loss: 4.6588 - val_acc: 0.1180\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.7253 - acc: 0.7957 - val_loss: 4.8321 - val_acc: 0.1363\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8243 - acc: 0.0097 - val_loss: 4.7648 - val_acc: 0.0153\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6649 - acc: 0.0430 - val_loss: 4.6310 - val_acc: 0.0320\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.1534 - acc: 0.0937 - val_loss: 4.1864 - val_acc: 0.0677\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.2373 - acc: 0.2243 - val_loss: 3.7638 - val_acc: 0.1410\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3227 - acc: 0.3983 - val_loss: 3.6240 - val_acc: 0.1703\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5760 - acc: 0.5795 - val_loss: 3.8733 - val_acc: 0.1730\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.8343 - acc: 0.7650 - val_loss: 3.9040 - val_acc: 0.2180\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8265 - acc: 0.0075 - val_loss: 4.7710 - val_acc: 0.0153\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6906 - acc: 0.0280 - val_loss: 4.6828 - val_acc: 0.0263\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2885 - acc: 0.0740 - val_loss: 4.3121 - val_acc: 0.0567\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4597 - acc: 0.1838 - val_loss: 3.8188 - val_acc: 0.1380\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.4872 - acc: 0.3670 - val_loss: 3.6831 - val_acc: 0.1587\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7163 - acc: 0.5410 - val_loss: 4.0492 - val_acc: 0.1623\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.9829 - acc: 0.7372 - val_loss: 3.8423 - val_acc: 0.1873\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8297 - acc: 0.0095 - val_loss: 4.7818 - val_acc: 0.0107\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7302 - acc: 0.0252 - val_loss: 4.7060 - val_acc: 0.0273\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.4312 - acc: 0.0662 - val_loss: 4.4131 - val_acc: 0.0547\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.6152 - acc: 0.1673 - val_loss: 3.9782 - val_acc: 0.1113\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6652 - acc: 0.3337 - val_loss: 3.6619 - val_acc: 0.1557\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8216 - acc: 0.5157 - val_loss: 3.6660 - val_acc: 0.1793\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.1192 - acc: 0.6932 - val_loss: 4.1933 - val_acc: 0.1660\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8276 - acc: 0.0093 - val_loss: 4.7761 - val_acc: 0.0107\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7139 - acc: 0.0232 - val_loss: 4.7059 - val_acc: 0.0300\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.4458 - acc: 0.0642 - val_loss: 4.5207 - val_acc: 0.0503\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.7841 - acc: 0.1427 - val_loss: 4.1704 - val_acc: 0.0877\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.9875 - acc: 0.2705 - val_loss: 4.0209 - val_acc: 0.1140\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.2015 - acc: 0.4378 - val_loss: 3.9106 - val_acc: 0.1520\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.4186 - acc: 0.6143 - val_loss: 4.0388 - val_acc: 0.1667\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.8445 - acc: 0.7625 - val_loss: 4.5997 - val_acc: 0.1840\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8337 - acc: 0.0078 - val_loss: 4.7907 - val_acc: 0.0113\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7668 - acc: 0.0163 - val_loss: 4.7645 - val_acc: 0.0157\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6650 - acc: 0.0318 - val_loss: 4.6601 - val_acc: 0.0283\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2495 - acc: 0.0798 - val_loss: 4.4094 - val_acc: 0.0573\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4416 - acc: 0.1900 - val_loss: 4.1375 - val_acc: 0.0863\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6083 - acc: 0.3517 - val_loss: 3.9466 - val_acc: 0.1403\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8507 - acc: 0.5100 - val_loss: 3.8581 - val_acc: 0.1653\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2274 - acc: 0.6655 - val_loss: 4.1589 - val_acc: 0.1723\n",
      "Epoch 9/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.6085 - acc: 0.8260 - val_loss: 4.2940 - val_acc: 0.1693\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8151 - acc: 0.0083 - val_loss: 4.7738 - val_acc: 0.0133\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6452 - acc: 0.0362 - val_loss: 4.6554 - val_acc: 0.0230\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.1565 - acc: 0.0855 - val_loss: 4.2675 - val_acc: 0.0787\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.2958 - acc: 0.2227 - val_loss: 4.0141 - val_acc: 0.1203\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3728 - acc: 0.3992 - val_loss: 3.7169 - val_acc: 0.1610\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.6057 - acc: 0.5705 - val_loss: 4.1539 - val_acc: 0.1590\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.9689 - acc: 0.7325 - val_loss: 4.0100 - val_acc: 0.1690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 27s 5ms/step - loss: 4.8261 - acc: 0.0077 - val_loss: 4.7823 - val_acc: 0.0117\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7323 - acc: 0.0208 - val_loss: 4.7334 - val_acc: 0.0190\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.5032 - acc: 0.0478 - val_loss: 4.5982 - val_acc: 0.0273\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.8878 - acc: 0.1232 - val_loss: 4.1590 - val_acc: 0.0823\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.0794 - acc: 0.2558 - val_loss: 4.1604 - val_acc: 0.0967\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.2759 - acc: 0.4210 - val_loss: 3.8736 - val_acc: 0.1507\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5128 - acc: 0.5932 - val_loss: 4.0074 - val_acc: 0.1567\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.9392 - acc: 0.7438 - val_loss: 4.3287 - val_acc: 0.1587\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8273 - acc: 0.0073 - val_loss: 4.7738 - val_acc: 0.0150\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6929 - acc: 0.0302 - val_loss: 4.6911 - val_acc: 0.0177\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3170 - acc: 0.0693 - val_loss: 4.4264 - val_acc: 0.0560\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4631 - acc: 0.1920 - val_loss: 3.9896 - val_acc: 0.1150\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5367 - acc: 0.3615 - val_loss: 3.6602 - val_acc: 0.1510\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7299 - acc: 0.5342 - val_loss: 3.8426 - val_acc: 0.1657\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.0693 - acc: 0.7060 - val_loss: 3.8960 - val_acc: 0.1847\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8208 - acc: 0.0098 - val_loss: 4.7718 - val_acc: 0.0127\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6687 - acc: 0.0302 - val_loss: 4.6542 - val_acc: 0.0337\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2337 - acc: 0.0860 - val_loss: 4.4129 - val_acc: 0.0517\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4553 - acc: 0.1957 - val_loss: 3.9702 - val_acc: 0.1023\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5569 - acc: 0.3522 - val_loss: 3.7755 - val_acc: 0.1477\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8385 - acc: 0.5125 - val_loss: 3.9004 - val_acc: 0.1643\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.1504 - acc: 0.6800 - val_loss: 4.0301 - val_acc: 0.1670\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8298 - acc: 0.0077 - val_loss: 4.7815 - val_acc: 0.0107\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7274 - acc: 0.0207 - val_loss: 4.7129 - val_acc: 0.0270\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.4476 - acc: 0.0635 - val_loss: 4.5077 - val_acc: 0.0487\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.7477 - acc: 0.1498 - val_loss: 4.0096 - val_acc: 0.1010\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.8096 - acc: 0.3025 - val_loss: 3.8431 - val_acc: 0.1403\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.0248 - acc: 0.4762 - val_loss: 3.6743 - val_acc: 0.1740\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2399 - acc: 0.6575 - val_loss: 3.9594 - val_acc: 0.1747\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.7738 - acc: 0.7843 - val_loss: 4.1097 - val_acc: 0.1737\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8237 - acc: 0.0088 - val_loss: 4.7818 - val_acc: 0.0120\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6877 - acc: 0.0282 - val_loss: 4.6963 - val_acc: 0.0243\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2741 - acc: 0.0810 - val_loss: 4.3885 - val_acc: 0.0603\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4085 - acc: 0.1988 - val_loss: 4.0119 - val_acc: 0.0977\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5520 - acc: 0.3602 - val_loss: 3.7217 - val_acc: 0.1550\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8159 - acc: 0.5190 - val_loss: 3.7445 - val_acc: 0.1620\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.1684 - acc: 0.6765 - val_loss: 4.0891 - val_acc: 0.1780\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8187 - acc: 0.0103 - val_loss: 4.7771 - val_acc: 0.0117\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6652 - acc: 0.0365 - val_loss: 4.6732 - val_acc: 0.0313\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.1530 - acc: 0.0963 - val_loss: 4.4086 - val_acc: 0.0640\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.3530 - acc: 0.2023 - val_loss: 3.9900 - val_acc: 0.1053\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5603 - acc: 0.3600 - val_loss: 3.7970 - val_acc: 0.1543\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8290 - acc: 0.5185 - val_loss: 3.9343 - val_acc: 0.1550\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.1965 - acc: 0.6697 - val_loss: 4.2817 - val_acc: 0.1640\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8215 - acc: 0.0085 - val_loss: 4.7788 - val_acc: 0.0117\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6874 - acc: 0.0265 - val_loss: 4.6958 - val_acc: 0.0247\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2857 - acc: 0.0780 - val_loss: 4.3708 - val_acc: 0.0540\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4949 - acc: 0.1827 - val_loss: 3.9348 - val_acc: 0.1070\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5855 - acc: 0.3473 - val_loss: 3.7109 - val_acc: 0.1517\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7697 - acc: 0.5248 - val_loss: 3.9325 - val_acc: 0.1667\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.0912 - acc: 0.6937 - val_loss: 3.9397 - val_acc: 0.1763\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8083 - acc: 0.0092 - val_loss: 4.7608 - val_acc: 0.0110\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.5977 - acc: 0.0433 - val_loss: 4.5569 - val_acc: 0.0397\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.8736 - acc: 0.1292 - val_loss: 4.0171 - val_acc: 0.1020\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.8335 - acc: 0.2977 - val_loss: 3.8911 - val_acc: 0.1423\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.9753 - acc: 0.4702 - val_loss: 3.5621 - val_acc: 0.1900\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2317 - acc: 0.6610 - val_loss: 3.7017 - val_acc: 0.1910\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.6887 - acc: 0.7998 - val_loss: 4.1731 - val_acc: 0.1913\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8196 - acc: 0.0082 - val_loss: 4.7726 - val_acc: 0.0130\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6692 - acc: 0.0308 - val_loss: 4.6647 - val_acc: 0.0247\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2323 - acc: 0.0790 - val_loss: 4.3963 - val_acc: 0.0663\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4730 - acc: 0.1867 - val_loss: 4.0459 - val_acc: 0.1047\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6343 - acc: 0.3382 - val_loss: 3.9564 - val_acc: 0.1427\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8433 - acc: 0.5133 - val_loss: 3.9941 - val_acc: 0.1483\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2391 - acc: 0.6578 - val_loss: 4.0280 - val_acc: 0.1637\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8167 - acc: 0.0073 - val_loss: 4.7745 - val_acc: 0.0117\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7059 - acc: 0.0263 - val_loss: 4.6981 - val_acc: 0.0273\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3329 - acc: 0.0753 - val_loss: 4.4527 - val_acc: 0.0490\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.6737 - acc: 0.1457 - val_loss: 4.0959 - val_acc: 0.0927\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.0240 - acc: 0.2572 - val_loss: 3.8441 - val_acc: 0.1113\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3456 - acc: 0.3950 - val_loss: 3.8875 - val_acc: 0.1430\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7028 - acc: 0.5445 - val_loss: 4.0075 - val_acc: 0.1597\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8286 - acc: 0.0063 - val_loss: 4.7783 - val_acc: 0.0167\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7155 - acc: 0.0262 - val_loss: 4.6801 - val_acc: 0.0283\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.4223 - acc: 0.0613 - val_loss: 4.4959 - val_acc: 0.0460\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.7045 - acc: 0.1550 - val_loss: 3.8971 - val_acc: 0.1170\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.8404 - acc: 0.3052 - val_loss: 3.6639 - val_acc: 0.1467\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.9979 - acc: 0.4815 - val_loss: 3.5305 - val_acc: 0.1720\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.3368 - acc: 0.6400 - val_loss: 3.6508 - val_acc: 0.2073\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.7434 - acc: 0.7915 - val_loss: 3.8190 - val_acc: 0.2237\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8227 - acc: 0.0108 - val_loss: 4.7652 - val_acc: 0.0167\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6853 - acc: 0.0283 - val_loss: 4.6385 - val_acc: 0.0347\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2440 - acc: 0.0828 - val_loss: 4.1753 - val_acc: 0.0863\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.2763 - acc: 0.2180 - val_loss: 3.5134 - val_acc: 0.1730\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3568 - acc: 0.3962 - val_loss: 3.5050 - val_acc: 0.1967\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5620 - acc: 0.5795 - val_loss: 3.4070 - val_acc: 0.2377\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.9388 - acc: 0.7388 - val_loss: 3.5604 - val_acc: 0.2290\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.4742 - acc: 0.8657 - val_loss: 4.0850 - val_acc: 0.2367\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8195 - acc: 0.0095 - val_loss: 4.7620 - val_acc: 0.0127\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6780 - acc: 0.0268 - val_loss: 4.6236 - val_acc: 0.0413\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2292 - acc: 0.0827 - val_loss: 4.1207 - val_acc: 0.0870\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.2814 - acc: 0.2198 - val_loss: 3.5799 - val_acc: 0.1587\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3244 - acc: 0.3985 - val_loss: 3.4650 - val_acc: 0.1900\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.6821 - acc: 0.5527 - val_loss: 3.3729 - val_acc: 0.2080\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.9755 - acc: 0.7285 - val_loss: 3.5456 - val_acc: 0.2127\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.5088 - acc: 0.8582 - val_loss: 3.9334 - val_acc: 0.2483\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8292 - acc: 0.0072 - val_loss: 4.7737 - val_acc: 0.0127\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6967 - acc: 0.0257 - val_loss: 4.6485 - val_acc: 0.0297\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2819 - acc: 0.0818 - val_loss: 4.2056 - val_acc: 0.0767\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4182 - acc: 0.1893 - val_loss: 3.6384 - val_acc: 0.1440\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5255 - acc: 0.3532 - val_loss: 3.3511 - val_acc: 0.1943\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7966 - acc: 0.5195 - val_loss: 3.3768 - val_acc: 0.2047\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.1628 - acc: 0.6792 - val_loss: 3.7941 - val_acc: 0.2137\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8213 - acc: 0.0088 - val_loss: 4.7598 - val_acc: 0.0137\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.6795 - acc: 0.0300 - val_loss: 4.6018 - val_acc: 0.0430\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.1851 - acc: 0.0918 - val_loss: 4.1324 - val_acc: 0.0913\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.2145 - acc: 0.2283 - val_loss: 3.6050 - val_acc: 0.1590\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.3769 - acc: 0.3855 - val_loss: 3.3040 - val_acc: 0.2053\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.6174 - acc: 0.5658 - val_loss: 3.4280 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 1.0260 - acc: 0.7128 - val_loss: 3.5695 - val_acc: 0.2470\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8229 - acc: 0.0087 - val_loss: 4.7770 - val_acc: 0.0157\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7185 - acc: 0.0270 - val_loss: 4.6945 - val_acc: 0.0377\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.4250 - acc: 0.0678 - val_loss: 4.4883 - val_acc: 0.0557\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.7119 - acc: 0.1572 - val_loss: 3.8708 - val_acc: 0.1173\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.8492 - acc: 0.3055 - val_loss: 3.6023 - val_acc: 0.1610\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.0977 - acc: 0.4618 - val_loss: 3.4522 - val_acc: 0.2093\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.3505 - acc: 0.6420 - val_loss: 3.8126 - val_acc: 0.1930\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.8535 - acc: 0.7622 - val_loss: 4.2451 - val_acc: 0.1957\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8202 - acc: 0.0100 - val_loss: 4.7773 - val_acc: 0.0133\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7014 - acc: 0.0282 - val_loss: 4.6822 - val_acc: 0.0267\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3513 - acc: 0.0785 - val_loss: 4.3223 - val_acc: 0.0690\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.6437 - acc: 0.1623 - val_loss: 3.7709 - val_acc: 0.1297\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.7095 - acc: 0.3258 - val_loss: 3.5115 - val_acc: 0.1773\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.9548 - acc: 0.4912 - val_loss: 3.5129 - val_acc: 0.1997\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2465 - acc: 0.6542 - val_loss: 3.7091 - val_acc: 0.1910\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8256 - acc: 0.0092 - val_loss: 4.7705 - val_acc: 0.0160\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7027 - acc: 0.0233 - val_loss: 4.6663 - val_acc: 0.0240\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3512 - acc: 0.0705 - val_loss: 4.3646 - val_acc: 0.0643\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.6096 - acc: 0.1713 - val_loss: 3.8835 - val_acc: 0.1267\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.7652 - acc: 0.3197 - val_loss: 3.5790 - val_acc: 0.1653\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 2.0462 - acc: 0.4703 - val_loss: 3.5520 - val_acc: 0.1963\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.3092 - acc: 0.6403 - val_loss: 3.6282 - val_acc: 0.2137\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.7308 - acc: 0.7980 - val_loss: 3.9764 - val_acc: 0.2237\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8148 - acc: 0.0100 - val_loss: 4.7596 - val_acc: 0.0163\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6671 - acc: 0.0340 - val_loss: 4.6284 - val_acc: 0.0273\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2470 - acc: 0.0772 - val_loss: 4.2844 - val_acc: 0.0773\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.5273 - acc: 0.1867 - val_loss: 3.8822 - val_acc: 0.1227\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6171 - acc: 0.3473 - val_loss: 3.5780 - val_acc: 0.1770\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.9298 - acc: 0.5013 - val_loss: 3.7681 - val_acc: 0.1767\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2983 - acc: 0.6538 - val_loss: 3.6720 - val_acc: 0.1980\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8279 - acc: 0.0093 - val_loss: 4.7778 - val_acc: 0.0153\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7122 - acc: 0.0270 - val_loss: 4.6869 - val_acc: 0.0307\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3715 - acc: 0.0702 - val_loss: 4.3024 - val_acc: 0.0753\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.5025 - acc: 0.1828 - val_loss: 3.8148 - val_acc: 0.1310\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6069 - acc: 0.3440 - val_loss: 3.6420 - val_acc: 0.1773\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7815 - acc: 0.5343 - val_loss: 3.8321 - val_acc: 0.1940\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.1510 - acc: 0.6865 - val_loss: 3.8759 - val_acc: 0.2063\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8242 - acc: 0.0077 - val_loss: 4.7734 - val_acc: 0.0123\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7029 - acc: 0.0255 - val_loss: 4.6701 - val_acc: 0.0310\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3394 - acc: 0.0818 - val_loss: 4.2966 - val_acc: 0.0690\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4844 - acc: 0.1838 - val_loss: 3.8875 - val_acc: 0.1327\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6007 - acc: 0.3503 - val_loss: 3.6773 - val_acc: 0.1733\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8709 - acc: 0.5163 - val_loss: 3.4693 - val_acc: 0.2030\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2147 - acc: 0.6675 - val_loss: 3.5479 - val_acc: 0.2157\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.6406 - acc: 0.8173 - val_loss: 4.0306 - val_acc: 0.2090\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.8216 - acc: 0.0078 - val_loss: 4.7741 - val_acc: 0.0137\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7077 - acc: 0.0290 - val_loss: 4.6809 - val_acc: 0.0270\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.3700 - acc: 0.0753 - val_loss: 4.3197 - val_acc: 0.0687\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.5948 - acc: 0.1677 - val_loss: 3.9036 - val_acc: 0.1207\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.7320 - acc: 0.3262 - val_loss: 3.6184 - val_acc: 0.1647\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.9319 - acc: 0.4980 - val_loss: 3.5229 - val_acc: 0.1850\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2627 - acc: 0.6498 - val_loss: 3.9121 - val_acc: 0.1863\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.7145 - acc: 0.7958 - val_loss: 4.3258 - val_acc: 0.2010\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8188 - acc: 0.0102 - val_loss: 4.7633 - val_acc: 0.0130\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6794 - acc: 0.0320 - val_loss: 4.6406 - val_acc: 0.0333\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2674 - acc: 0.0812 - val_loss: 4.2071 - val_acc: 0.0727\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4237 - acc: 0.1973 - val_loss: 3.7142 - val_acc: 0.1363\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5255 - acc: 0.3585 - val_loss: 3.4884 - val_acc: 0.1843\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7618 - acc: 0.5393 - val_loss: 3.4430 - val_acc: 0.2230\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.1324 - acc: 0.6877 - val_loss: 3.7624 - val_acc: 0.2003\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.5882 - acc: 0.8373 - val_loss: 4.0026 - val_acc: 0.2223\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8254 - acc: 0.0088 - val_loss: 4.7645 - val_acc: 0.0137\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6788 - acc: 0.0342 - val_loss: 4.6426 - val_acc: 0.0360\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2334 - acc: 0.0875 - val_loss: 4.1780 - val_acc: 0.0893\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.3150 - acc: 0.2163 - val_loss: 3.6105 - val_acc: 0.1637\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3637 - acc: 0.3903 - val_loss: 3.2931 - val_acc: 0.2073\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7360 - acc: 0.5278 - val_loss: 3.4162 - val_acc: 0.2237\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.0480 - acc: 0.7108 - val_loss: 3.6824 - val_acc: 0.2327\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8205 - acc: 0.0120 - val_loss: 4.7557 - val_acc: 0.0187\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6262 - acc: 0.0450 - val_loss: 4.5579 - val_acc: 0.0463\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.9801 - acc: 0.1243 - val_loss: 3.8996 - val_acc: 0.1167\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.8981 - acc: 0.2902 - val_loss: 3.4321 - val_acc: 0.1747\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.0719 - acc: 0.4620 - val_loss: 3.4769 - val_acc: 0.1957\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.3299 - acc: 0.6422 - val_loss: 3.4780 - val_acc: 0.2373\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8299 - acc: 0.0090 - val_loss: 4.7823 - val_acc: 0.0137\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7377 - acc: 0.0238 - val_loss: 4.7204 - val_acc: 0.0243\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.5184 - acc: 0.0510 - val_loss: 4.4919 - val_acc: 0.0450\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.9667 - acc: 0.1133 - val_loss: 4.1087 - val_acc: 0.0973\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.1038 - acc: 0.2548 - val_loss: 3.7065 - val_acc: 0.1417\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.2830 - acc: 0.4208 - val_loss: 3.5337 - val_acc: 0.1800\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.6132 - acc: 0.5807 - val_loss: 3.6549 - val_acc: 0.2003\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.8729 - acc: 0.7620 - val_loss: 4.2302 - val_acc: 0.1927\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8303 - acc: 0.0063 - val_loss: 4.7699 - val_acc: 0.0117\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7044 - acc: 0.0288 - val_loss: 4.6594 - val_acc: 0.0380\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3225 - acc: 0.0793 - val_loss: 4.2063 - val_acc: 0.0953\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4532 - acc: 0.1957 - val_loss: 3.6165 - val_acc: 0.1617\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6593 - acc: 0.3355 - val_loss: 3.4343 - val_acc: 0.1977\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8017 - acc: 0.5263 - val_loss: 3.5494 - val_acc: 0.2197\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.1454 - acc: 0.6843 - val_loss: 3.6212 - val_acc: 0.2140\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8261 - acc: 0.0103 - val_loss: 4.7741 - val_acc: 0.0130\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7034 - acc: 0.0287 - val_loss: 4.6710 - val_acc: 0.0313\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3437 - acc: 0.0743 - val_loss: 4.1679 - val_acc: 0.0910\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4528 - acc: 0.1945 - val_loss: 3.5927 - val_acc: 0.1563\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5196 - acc: 0.3650 - val_loss: 3.6093 - val_acc: 0.1793\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7795 - acc: 0.5337 - val_loss: 3.4165 - val_acc: 0.2320\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.0710 - acc: 0.7070 - val_loss: 3.7177 - val_acc: 0.2327\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.5750 - acc: 0.8405 - val_loss: 3.9677 - val_acc: 0.2503\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8177 - acc: 0.0093 - val_loss: 4.7502 - val_acc: 0.0177\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6454 - acc: 0.0353 - val_loss: 4.5555 - val_acc: 0.0447\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.0362 - acc: 0.1107 - val_loss: 3.8743 - val_acc: 0.1153\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.0889 - acc: 0.2518 - val_loss: 3.4287 - val_acc: 0.1737\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.2433 - acc: 0.4230 - val_loss: 3.4102 - val_acc: 0.1980\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5073 - acc: 0.5933 - val_loss: 3.2497 - val_acc: 0.2630\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.9417 - acc: 0.7405 - val_loss: 3.7326 - val_acc: 0.2403\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.4454 - acc: 0.8762 - val_loss: 4.0595 - val_acc: 0.2567\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8167 - acc: 0.0098 - val_loss: 4.7577 - val_acc: 0.0153\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6726 - acc: 0.0312 - val_loss: 4.6142 - val_acc: 0.0443\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2151 - acc: 0.0890 - val_loss: 4.0502 - val_acc: 0.1043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.3272 - acc: 0.2173 - val_loss: 3.6718 - val_acc: 0.1537\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.4632 - acc: 0.3747 - val_loss: 3.2351 - val_acc: 0.2240\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7529 - acc: 0.5415 - val_loss: 3.3953 - val_acc: 0.2303\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.0483 - acc: 0.7183 - val_loss: 3.7306 - val_acc: 0.2320\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8320 - acc: 0.0067 - val_loss: 4.7789 - val_acc: 0.0137\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7395 - acc: 0.0177 - val_loss: 4.7197 - val_acc: 0.0233\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.5307 - acc: 0.0553 - val_loss: 4.4750 - val_acc: 0.0500\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.8403 - acc: 0.1338 - val_loss: 3.8276 - val_acc: 0.1170\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.9471 - acc: 0.2780 - val_loss: 3.5010 - val_acc: 0.1777\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.1850 - acc: 0.4378 - val_loss: 3.4124 - val_acc: 0.2097\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5125 - acc: 0.5980 - val_loss: 3.6418 - val_acc: 0.2137\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.0119 - acc: 0.7242 - val_loss: 3.7960 - val_acc: 0.2140\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8312 - acc: 0.0067 - val_loss: 4.7820 - val_acc: 0.0133\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7289 - acc: 0.0228 - val_loss: 4.7093 - val_acc: 0.0260\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.5228 - acc: 0.0550 - val_loss: 4.4301 - val_acc: 0.0537\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.8467 - acc: 0.1355 - val_loss: 3.9185 - val_acc: 0.1103\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.9811 - acc: 0.2763 - val_loss: 3.5386 - val_acc: 0.1773\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.1810 - acc: 0.4377 - val_loss: 3.4190 - val_acc: 0.2163\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.4174 - acc: 0.6228 - val_loss: 3.5760 - val_acc: 0.2230\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.7826 - acc: 0.7848 - val_loss: 4.1130 - val_acc: 0.2117\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8165 - acc: 0.0102 - val_loss: 4.7597 - val_acc: 0.0147\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6485 - acc: 0.0367 - val_loss: 4.5691 - val_acc: 0.0423\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.0776 - acc: 0.1012 - val_loss: 3.9578 - val_acc: 0.1197\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.0634 - acc: 0.2592 - val_loss: 3.5366 - val_acc: 0.1703\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.3298 - acc: 0.4113 - val_loss: 3.3237 - val_acc: 0.2033\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5736 - acc: 0.5792 - val_loss: 3.4158 - val_acc: 0.2287\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.9252 - acc: 0.7443 - val_loss: 3.8360 - val_acc: 0.2150\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8352 - acc: 0.0082 - val_loss: 4.7657 - val_acc: 0.0160\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7063 - acc: 0.0243 - val_loss: 4.6657 - val_acc: 0.0277\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3568 - acc: 0.0743 - val_loss: 4.2575 - val_acc: 0.0737\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.5118 - acc: 0.1798 - val_loss: 3.6723 - val_acc: 0.1507\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6993 - acc: 0.3242 - val_loss: 3.4354 - val_acc: 0.1877\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.9132 - acc: 0.5023 - val_loss: 3.3584 - val_acc: 0.2130\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2640 - acc: 0.6570 - val_loss: 3.7392 - val_acc: 0.2193\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.7162 - acc: 0.7965 - val_loss: 3.7001 - val_acc: 0.2613\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8321 - acc: 0.0075 - val_loss: 4.7805 - val_acc: 0.0107\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7397 - acc: 0.0222 - val_loss: 4.7236 - val_acc: 0.0303\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.5399 - acc: 0.0555 - val_loss: 4.5038 - val_acc: 0.0497\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.8894 - acc: 0.1313 - val_loss: 4.0446 - val_acc: 0.1057\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.9665 - acc: 0.2817 - val_loss: 3.6842 - val_acc: 0.1623\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.2061 - acc: 0.4343 - val_loss: 3.5821 - val_acc: 0.1883\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.4808 - acc: 0.6053 - val_loss: 3.9436 - val_acc: 0.1847\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.8516 - acc: 0.7645 - val_loss: 3.9861 - val_acc: 0.2290\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8210 - acc: 0.0098 - val_loss: 4.7801 - val_acc: 0.0087\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.7344 - acc: 0.0200 - val_loss: 4.7164 - val_acc: 0.0263\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.5370 - acc: 0.0530 - val_loss: 4.4764 - val_acc: 0.0460\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 4.0094 - acc: 0.1133 - val_loss: 3.9646 - val_acc: 0.1117\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.2834 - acc: 0.2250 - val_loss: 3.7351 - val_acc: 0.1387\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6151 - acc: 0.3525 - val_loss: 3.7456 - val_acc: 0.1560\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.9066 - acc: 0.5102 - val_loss: 3.8266 - val_acc: 0.2007\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8206 - acc: 0.0077 - val_loss: 4.7671 - val_acc: 0.0133\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6927 - acc: 0.0290 - val_loss: 4.6547 - val_acc: 0.0360\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2919 - acc: 0.0912 - val_loss: 4.2289 - val_acc: 0.0900\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.3867 - acc: 0.2067 - val_loss: 3.6606 - val_acc: 0.1587\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5085 - acc: 0.3648 - val_loss: 3.4359 - val_acc: 0.1940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7589 - acc: 0.5317 - val_loss: 3.5851 - val_acc: 0.1903\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.0826 - acc: 0.7060 - val_loss: 3.6739 - val_acc: 0.2300\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8212 - acc: 0.0097 - val_loss: 4.7632 - val_acc: 0.0180\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6575 - acc: 0.0345 - val_loss: 4.5917 - val_acc: 0.0427\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.1075 - acc: 0.1002 - val_loss: 3.9089 - val_acc: 0.1247\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.0764 - acc: 0.2527 - val_loss: 3.5986 - val_acc: 0.1780\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.2108 - acc: 0.4212 - val_loss: 3.2796 - val_acc: 0.2340\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5271 - acc: 0.5943 - val_loss: 3.3887 - val_acc: 0.2417\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.9230 - acc: 0.7475 - val_loss: 3.6446 - val_acc: 0.2270\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8182 - acc: 0.0107 - val_loss: 4.7555 - val_acc: 0.0213\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6441 - acc: 0.0405 - val_loss: 4.5962 - val_acc: 0.0423\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.1307 - acc: 0.0992 - val_loss: 4.0902 - val_acc: 0.0990\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.1565 - acc: 0.2500 - val_loss: 3.5063 - val_acc: 0.1673\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.2253 - acc: 0.4287 - val_loss: 3.3477 - val_acc: 0.2137\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.5088 - acc: 0.5977 - val_loss: 3.6757 - val_acc: 0.2210\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.8699 - acc: 0.7563 - val_loss: 3.8886 - val_acc: 0.2347\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8320 - acc: 0.0082 - val_loss: 4.7686 - val_acc: 0.0137\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6988 - acc: 0.0283 - val_loss: 4.6508 - val_acc: 0.0367\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3437 - acc: 0.0728 - val_loss: 4.1652 - val_acc: 0.0897\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4704 - acc: 0.1922 - val_loss: 3.6689 - val_acc: 0.1517\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6544 - acc: 0.3420 - val_loss: 3.2543 - val_acc: 0.2103\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8539 - acc: 0.5085 - val_loss: 3.2932 - val_acc: 0.2277\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.2204 - acc: 0.6777 - val_loss: 3.4772 - val_acc: 0.2283\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8221 - acc: 0.0078 - val_loss: 4.7734 - val_acc: 0.0150\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.7091 - acc: 0.0247 - val_loss: 4.6845 - val_acc: 0.0327\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.3870 - acc: 0.0750 - val_loss: 4.3369 - val_acc: 0.0723\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.5898 - acc: 0.1772 - val_loss: 3.7560 - val_acc: 0.1383\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.6563 - acc: 0.3358 - val_loss: 3.5877 - val_acc: 0.1653\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.8631 - acc: 0.5073 - val_loss: 3.3480 - val_acc: 0.2193\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.1864 - acc: 0.6797 - val_loss: 3.5793 - val_acc: 0.2233\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.6192 - acc: 0.8253 - val_loss: 4.1481 - val_acc: 0.2317\n",
      "4222/4222 [==============================] - 7s 2ms/step\n",
      "Train on 6000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.8201 - acc: 0.0102 - val_loss: 4.7618 - val_acc: 0.0180\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.6807 - acc: 0.0355 - val_loss: 4.6459 - val_acc: 0.0373\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 4.2804 - acc: 0.0857 - val_loss: 4.1293 - val_acc: 0.0993\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 3.4178 - acc: 0.2080 - val_loss: 3.6143 - val_acc: 0.1593\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 2.5005 - acc: 0.3785 - val_loss: 3.2861 - val_acc: 0.2217\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.7198 - acc: 0.5520 - val_loss: 3.4190 - val_acc: 0.2223\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 1.1120 - acc: 0.7012 - val_loss: 3.3914 - val_acc: 0.2493\n",
      "4222/4222 [==============================] - 7s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for fov in FOV_VALS:\n",
    "    train_dir = os.path.join(PARENT_DIR, 'train', str(fov))\n",
    "    \n",
    "    for diverse_similar in ['diverse', 'similar']:\n",
    "        os.chdir(train_dir)\n",
    "        if diverse_similar not in os.listdir():\n",
    "            os.mkdir(diverse_similar)\n",
    "        train_x = np.load(diverse_similar + '-images.npy') / 255.\n",
    "        train_y = np.load(diverse_similar + '-labels.npy')\n",
    "        \n",
    "        train_ind = np.where(np.isin(train_y, dogs_subset))[0]\n",
    "        train_x = train_x[train_ind, :, :, :]\n",
    "        train_y = train_y[train_ind]\n",
    "        \n",
    "        y_train = np.asarray([y_dict[x] for x in train_y])\n",
    "        y_train = np_utils.to_categorical(y_train)\n",
    "        \n",
    "        os.chdir(diverse_similar)\n",
    "        \n",
    "        for i in range(RUNS):\n",
    "            if str(i) not in os.listdir():\n",
    "                os.mkdir(str(i))\n",
    "            \n",
    "            vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "            model = models.Sequential()\n",
    "            model.add(vgg_conv)\n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dense(4096, activation='relu'))\n",
    "            model.add(layers.Dense(4096, activation='relu'))\n",
    "            model.add(layers.Dense(SUBSET_SIZE, activation='softmax'))\n",
    "            model.compile(loss='categorical_crossentropy', \n",
    "                          optimizer=optimizers.SGD(lr=.001, momentum=.9), \n",
    "                          metrics=['acc'])\n",
    "            \n",
    "        \n",
    "            tensorboard = TensorBoard(log_dir=os.path.join(train_dir, diverse_similar, str(i)))\n",
    "            checkpoint = ModelCheckpoint(os.path.join(train_dir, diverse_similar, str(i)) + '/model-{epoch:04d}.hdf5', \n",
    "                                         save_weights_only=False,\n",
    "                                         save_best_only=False,\n",
    "                                         mode='auto', \n",
    "                                         period=1)\n",
    "            earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=2)\n",
    "            \n",
    "            model.fit(train_x, y_train, \n",
    "                      validation_data=(val_x, y_val), \n",
    "                      epochs=100, \n",
    "                      batch_size=BATCH_SIZE, \n",
    "                      verbose=1,\n",
    "                      shuffle=True, \n",
    "                      callbacks=[tensorboard, checkpoint, earlystopping])\n",
    "            loss, accuracy = model.evaluate(test_x, y_test)\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            \n",
    "            K.clear_session()\n",
    "            del model\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov_vals = np.repeat(FOV_VALS, [int(i) for i in np.ones(len(FOV_VALS)) * 2 * RUNS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diverse_similar = np.tile(['diverse', 'diverse', 'diverse', 'diverse', \n",
    "#                            'similar', 'similar', 'similar', 'similar'], len(FOV_VALS))\n",
    "diverse_similar = np.tile(np.concatenate([np.repeat('diverse', RUNS), \n",
    "                                          np.repeat('similar', RUNS)]), \n",
    "                          len(FOV_VALS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({'fov': fov_vals, \n",
    "                           'train_set_type': diverse_similar, \n",
    "                           'loss': losses, \n",
    "                           'accuracy': accuracies})\n",
    "results_df.to_csv('/media/johnkoo/data/stanford-dogs-dataset/results-diversity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcfd866ccf8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x='fov', y='accuracy', hue='train_set_type', data=results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_agg_df = (\n",
    "    results_df.\n",
    "    groupby(['fov', 'train_set_type']).\n",
    "    agg({'accuracy': ['mean', 'std']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcf79e3c048>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pointplot(x='fov', y='accuracy', hue='train_set_type', data=results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
